<!DOCTYPE html>
<html lang="de">
<head>
<meta charset="utf-8"/>
<title>Parallelprogrammierung &#x2013; Einstieg</title>
<meta name="author" content="(Johannes Brauer)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="./reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="./reveal.js/css/theme/simple.css" id="theme"/>

<link rel="stylesheet" href="./mycss/myrevealstyle.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = './reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel="stylesheet" type="text/css" href="mycss/mystyle.css" />
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">Parallelprogrammierung &#x2013; Einstieg</h1><h2 class="author">Johannes Brauer</h2><p class="date">Created: 2019-07-19 Fri 16:28</p>
</section>

<section>
<section id="org485072e">
<h2 id="org485072e">Ziele</h2>
<ul>
<li>Kennenlernen der Grundbegriffe der Parallelprogrammierung</li>
<li>Unterscheiden lernen zwischen Nebenläufigkeit und Parallelität</li>
<li>Überblick gewinnen über Formen der Unterstützung von
Parallelprogrammierung durch Hardware und Software</li>

</ul>
</section>
</section>
<section>
<section id="orga03ac94">
<h2 id="orga03ac94">Warum Parallelprogrammierung?</h2>
<div class="outline-text-2" id="text-orga03ac94">
</div>
</section>
<section id="orgc14f619">
<h3 id="orgc14f619">Technische Gründe</h3>
<ul>
<li>Erhöhung der Rechenleistung durch Erhöhung der Taktfrequenzen stösst
technisch an Grenzen.</li>
<li>Mooresche Gesetz gilt aber noch.</li>
<li>Folge: Prozessoren mit mehreren Kernen.</li>
<li>Leistungssteigerung durch Parallelarbeit</li>
<li>Geschwindigkeitssteigerung bei \(n\) Kernen theoretisch n-fach
<ul>
<li>praktisch nicht erreichbar</li>
<li>Anwendungsentwicklung auf Parallelprogrammierung nicht vorbereitet</li>

</ul></li>

</ul>
</section>
<section id="orgec469ad">
<h3 id="orgec469ad">Computer im Wandel der Jahrzehnte</h3>

<div class="figure">
<p><img src="./Abbildungen/computervon60Jahrenundjetzt.jpg" alt="computervon60Jahrenundjetzt.jpg" width="400px" />
</p>
</div>
</section>
<section >
<ul>
<li>Ein iPhone enthält ca. 1 Milliarde Transistoren.</li>
<li>Um diese Rechenleistung mit der Technologie der 1950er Jahre zu
bauen, bräuchte es:
<ul>
<li>1 Milliarde Elektronenröhren</li>
<li>170 vehicle assembly buildings, um sie unterzubringen</li>
<li>1 Terawatt Leistung, um sie zu betreiben</li>
<li>das entspräche 500 2-Gigawatt-Kernkraftwerken für ca. 50 Milliarden Euro</li>
<li>das entspräche dem Weltbruttosozialprodukt von 60 Jahren</li>

</ul></li>
<li>Smartphones realisieren eine Steigerung der Rechenleistung um den
Faktor \(10^{22}\) verglichen mit der Technologie vor 60 Jahren.</li>

</ul>

<p>
Welche Fortschritte gibt es in dieser Zeit in der Software?
</p>
</section>
<section id="org05827dc">
<h4 id="org05827dc">Geschichte der Rechensysteme</h4>
<p>
(vgl. <a class='org-ref-reference' href="#Bengel2015">Bengel2015</a>)
</p>
<dl>
<dt>1970 &#x2013; Stapelverarbeitung</dt><dd><ul>
<li>Einlesen von Aufträgen (jobs) und Bearbeitung durch die Maschine</li>
<li>Job-Scheduler bestimmt die Abarbeitungsreihenfolge</li>
<li><i>non-blocking IO</i> kommt zum Einsatz (Nebenläufigkeit)</li>

</ul></dd>
<dt>1975 &#x2013; Timesharing-Systeme</dt><dd><ul>
<li>interaktives Arbeiten mittels Kommandozeilen-Befehlen</li>
<li>Mehrbenutzerbetrieb</li>
<li>Zuteilung von Zeitscheiben</li>

</ul></dd>
<dt>1980 &#x2013; Personal Computer und Workstation</dt><dd><ul>
<li>hohe Rechenleistung am Arbeitsplatz</li>
<li>Rückkehr zum Einbenutzerbetrieb</li>
<li>Kommandozeile + graphische Benutzungsoberflächen</li>
<li>Insellösungen &#x2013; kein Zugriff auf gemeinsame Betriebsmittel</li>
<li>Notlösung: peer-to-peer-Netze</li>

</ul></dd>

</dl>
</section>
<section >
<dl>
<dt>1985 &#x2013; Client-Server-Systeme</dt><dd><ul>
<li>Zentralisierung bestimmter Dienste auf dedizierten Rechnern (server)</li>
<li>neue Betriebssystemkonzepte für Netzwerknutzung erforderlich</li>

</ul></dd>
<dt>1990 &#x2013; Cluster-Systeme</dt><dd><ul>
<li>auch <i>Verteilte Systeme</i></li>
<li>mehrere Rechner bzw. Multiprozessorsysteme teilen sich die Dienstserbringung</li>
<li>zur Erhöhung von Leistung und Ausfallsicherheit</li>
<li>Load Balancing Cluster / Serverfarmen</li>
<li>High Performance Computing (HPC) Cluster
<ul>
<li>Geschwindigkeitssteigerung durch Parallelisierung von Aufgaben</li>
<li>bei Ausfall eines Systems übernimmt ein anderes Cluster-Mitglied
dessen Aufgaben</li>

</ul></li>

</ul></dd>
<dt>1995 &#x2013; Peer-to-Peer-Systeme</dt><dd><ul>
<li>jede Maschine kann Client und Server sein</li>
<li>höhere Ausfallsicherheit</li>

</ul></dd>

</dl>
</section>
<section >
<dl>
<dt>2005 &#x2013; Cloud-Systeme oder Cloud-Computing</dt><dd><ul>
<li>Rezentralisierung der Rechenleistung durch Virtualisierung</li>
<li>Zugriff auf Ressourcen über Internet oder Intranet</li>

</ul></dd>

</dl>
</section>
<section id="org4264642">
<h4 id="org4264642">Geschichte der Technologie von Prozessoren und Speicherchips</h4>
<ul>
<li>Mooresches Gesetz von 1965: Verdoppelung der Anzahl der Transistoren
auf einem Chip ca. alle 18 Monate &#x2013; gilt noch heute</li>
<li>Entwicklung der Mikroprozessoren am Beispiel von Intel
<ul>
<li>1971: Intel 4004, Transistoren: 2300, Taktrate: 108 kHz</li>
<li>1999: Pentium III, Transistoren: 9.500.000, Taktrate: bis 1 GHz</li>
<li>2000 bis 2008: Pentium 4, Transistoren: 42.000.000, Taktrate: bis
3,8 GHz</li>

</ul></li>
<li>Speicherkapazität pro Chip
<ul>
<li>1970: 1 Kilobit</li>
<li>heute: 1 Gigabit</li>

</ul></li>
<li>Preisverfall bei MIPS und Kosten pro Bit</li>

</ul>
</section>
<section >
<ul>
<li>Enwicklung der Mikroprozessortechnik</li>

</ul>

<div class="figure">
<p><img src="./Abbildungen/CPU-Moore.png" alt="CPU-Moore.png" width="400px" />
</p>
</div>
</section>
</section>
<section>
<section id="org22ba5ed">
<h2 id="org22ba5ed">Worüber reden wir?</h2>
<div class="outline-text-2" id="text-org22ba5ed">
</div>
</section>
<section id="orgdd33d21">
<h3 id="orgdd33d21">Nebenläufigkeit versus Parallelität</h3>
<ul>
<li><b>Nebenläufigkeit</b> (concurrency) = Handhabung mehrerer unabhängiger
Aufgaben während einer Zeitspanne, z.&nbsp;B. in Anwendungen mit
Benutzungsoberfläche oder Netzwerkanwendungen.
<ul>
<li>Die Aufgaben konkurrieren dabei um Ressourcen.</li>
<li>Die Resultate nebenläufiger Aufgaben beeinflussen häufig das
Verhalten anderer nebenläufiger Aufgaben.</li>
<li>Folge: potentieller Nicht-Determinismus</li>

</ul></li>
<li><b>Parallelität</b> = Aufteilung einer Aufgabe in mehrere Teilaufgaben,
die zur gleichen Zeit ablaufen.
<ul>
<li>Gewöhnlich arbeiten die Teilaufgaben auf ein gemeinsames Ziel hin,
beinflussen sich daher in der Regel nicht.</li>
<li>Folge: Determinismus bleibt erhalten.</li>
<li>Parallele Algorithmen (Parallelisierung von Algorithmen) stellen
ein Teilgebiet der Algorithmik dar und ist hier nur Randthema.</li>

</ul></li>

</ul>
</section>
<section id="orgb4c30bb">
<h3 id="orgb4c30bb">Parallelität in der Nebenläufigkeit</h3>
<ul>
<li>Die Bearbeitung nebenläufiger, also in der gleichen Zeitspanne
ablaufender Aufgaben kann auf zwei Arten erfolgen:
<ul>
<li>echt parallel oder</li>
<li>quasi-parallel (überlappend)</li>

</ul></li>
<li><b>Beispiel</b></li>

</ul>
<pre class="example">
      client requests  +------------+   ## Task1: verarbeite Request1
    ------------------&gt;| web server |   ## Task2: verarbeite Request2
                       +------------+      ...
</pre>
<ul>
<li><p>
<b>1. Szenario</b>: Einprozessormaschine mit Zeitscheiben-Scheduling
</p>
<ul>
<li>Jeder Task steht ein festes Zeitquantum zur Verfügung bevor
ihr der Prozessor entzogen wird:</li>

</ul>
<pre class="example">
            Zeitspanne (ZS): Startzeitpunkt bis Endzeitpunt
Startzeitpunkt                                    Endzeitpunt
         |                                         |
         +-----------------------------------------+   ## Jeder Stern * steht für einen
          \             /\         /\             /       Takt der Systemuhr
           ****Task1****  **Task2**  ****Task1****     ## Task1 (16 Takte) und Task2 
                                                         (4 Takte) teilen Prozessor
</pre></li>

</ul>
</section>
<section >
<ul>
<li>Task1 und Task2 werden während der Zeitspanne ZS nebenläufig (überlappend) aber
nicht parallel verarbeitet.</li>
<li>Nebenläufigkeit ohne Parallelität</li>

</ul>
<ul>
<li><p>
<b>2. Szenario:</b> eine Zwei-Prozessormaschine
</p>
<pre class="example">
                 Zeitspanne 
Startzeitpunkt                Endzeitpunt
         |                       |
         +-----------------------+
          \                     /
           ********Task1********      ### Ausführung auf Prozessor1
		   \         /
		    **Task2**         ### Ausführung auf Prozessor2
</pre>
<ul>
<li>Task1 und Task2 werden während der Zeitspanne nebenläufig <b>und</b>
parallel (für 4 Zeitschritte) verarbeitet.</li>
<li>Der Durchsatz der Maschine wird verbessert:
<ul>
<li>1. Szenario erfordert 20 Takte ingesamt.</li>
<li>2. Szenario erfordert 16 Takte.</li>

</ul></li>
<li>Der Zeitaufwand für die einzelne Task bleibt gleich.</li>

</ul></li>

</ul>
</section>
<section id="org66c90d6">
<h3 id="org66c90d6">Probleme</h3>
<ul>
<li>Das Schreiben nebenläufiger Programme gehört zu den schwierigsten
Aufgaben, denen Programmierer begegnen.
<ul>
<li>Ihr Verhalten ist schwer zu erklären bzw. vorherzusagen.</li>
<li>Sind häufig nicht-deterministisch.</li>
<li>Können Verklemmungen (dealocks) verursachen.</li>
<li>Können Wettlaufsituationen (race conditions) verursachen.</li>
<li>Teilaufgaben können „verhungern“.</li>

</ul></li>
<li>Fehlverhalten schwer zu entdecken (zu reproduzieren).</li>
<li>Mutation ist die Ursache vieler Probleme.</li>

<li>Alltagsbeispiele:
<ul>
<li>Toilette in der WG</li>
<li>Schalterhalle einer Bank</li>

</ul></li>

</ul>
</section>
</section>
<section>
<section id="org31e345d">
<h2 id="org31e345d">Mehrprozessorsysteme</h2>
<p>
(Die Ausführungen in diesem lehnen sich an ein Vorlesungsskript von
Uwe Neuhaus an)
</p>
</section>
<section id="orgec934ad">
<h3 id="orgec934ad">Prinzip</h3>
<ul>
<li>Mehrprozessorsysteme besitzen mehrere, eng gekoppelte Prozessoren</li>
<li>Eng gekoppelt &#x2013; Prozessoren nutzen gemeinsam Hauptspeicher und
Systemtakt. Die Kommunikation zwischen den Prozessoren findet
üblicherweise über den gemeinsam genutzten Speicher statt.</li>
<li>Vorteile von Mehrprozessorsystemen: Erhöhter Durchsatz
<ul>
<li>Verbessertes Preis/Leistungsverhältnis</li>
<li>Höhere Zuverlässigkeit
<ul>
<li>stufenweiser Leistungsverlust(gracefuldegradation)</li>
<li>Ausfallsicherheit(fail-softsystems)</li>

</ul></li>

</ul></li>

</ul>
</section>
<section id="orgcfbc858">
<h3 id="orgcfbc858">Varianten</h3>
<dl>
<dt>Symmetric multiprocessing (SMP)</dt><dd><ul>
<li>Auf jedem Prozessor läuft das identische Betriebssystem</li>
<li>Mehrere Prozesse können ohne Leistungsverlust ablaufen</li>
<li>Die meisten modernen Betriebssysteme unterstützen SMP</li>

</ul></dd>
<dt>Asymmetric multiprocessing</dt><dd><ul>
<li>Jeder Prozessor hat eine spezielle Aufgabe. Ein Master-Prozessor
verteilt Aufgaben an die anderen (möglicherweise spezialisierten)
 Slave- Prozessoren.</li>
<li>Beispiel: Grafikprozessoren</li>

</ul></dd>

</dl>
</section>
<section id="orge0c8182">
<h3 id="orge0c8182">Architektur bei symmetrischen Mehrprozessorsystemen</h3>

<div class="figure">
<p><img src="./Abbildungen/mehrprozessorarchitektur.png" alt="mehrprozessorarchitektur.png" width="600px" />
</p>
</div>

<p>
<b>Achtung</b>: Zugriff auf den Hauptspeicher über gemeinsamen Bus kann zum
Flaschenhals werden.
</p>

</section>
<section id="org25c914c">
<h3 id="org25c914c">Rechnerarchitekturen für parallele und verteilte Systeme</h3>
<p>
(vgl. <a class='org-ref-reference' href="#Bengel2015">Bengel2015</a>, <a class='org-ref-reference' href="#Kalin2015">Kalin2015</a>)
</p>
</section>
<section id="org6ed0b5c">
<h4 id="org6ed0b5c">Taxonomie von parallelen Rechnerarchitekturen nach Flynn</h4>
<p>
(vgl. <a class='org-ref-reference' href="#Flynn1972">Flynn1972</a>)
</p>
<ul>
<li>Anmerkungen:
<ul>
<li>Die Taxonomie sagt nichts darüber aus, ob die Architektur ein
einzelnes oder ein verteiltes System beschreibt.</li>
<li>TDie Taxonomie ist schon recht alt, wird aber als Referenz nach
wie vor benutzt.</li>

</ul></li>
<li>Abkürzungen:<br />
D = Daten<br />
I = Befehle (Instruktionen)<br />
P = Prozessor<br />
S steht für <i>single</i>, M für <i>multiple</i>.
<ul>
<li>Parallelität im Sinne dieser Taxonomie erfordert immer mehrere
Prozessoren (P).</li>

</ul></li>

</ul>
</section>
<section >
<dl>
<dt>SISD: single instruction, single data</dt><dd><ul>
<li>keine Form von Parallelität</li>

</ul></dd>

</dl>
<pre class="example">
   +----------+    +---+    +----------+
   | D source |---&gt;| P |&lt;---| I source |                 
   +----------+    +---+    +----------+
</pre>
<dl>
<dt>SIMD: single instruction, multiple data</dt><dd><ul>
<li>Unterstützung in verschiedenen Programmiersprachen</li>
<li>heutzutage besonders relevant</li>

</ul></dd>

</dl>
<pre class="example">
   +----------+    +---+
   | D source |---&gt;| P |&lt;---+
   +----------+    +---+    |
   +----------+    +---+    |  +----------+
   | D source |---&gt;| P |&lt;---+--| I source |               
   +----------+    +---+    |  +----------+
   +----------+    +---+    |
   | D source |---&gt;| P |&lt;---+
   +----------+    +---+
</pre>
</section>
<section >
<dl>
<dt>MISD: multiple instruction, single data</dt><dd><ul>
<li>kaum praktische Bedeutung</li>

</ul></dd>

</dl>
<pre class="example">
                      +---+    +----------+
                 +---&gt;| P |&lt;---| I source |
                 |    +---+    +----------+
   +----------+  |    +---+    +----------+
   | D source |--+---&gt;| P |&lt;---| I source |               
   +----------+  |    +---+    +----------+ 
                 |    +---+    +----------+
                 +---&gt;| P |&lt;---| I source | 
                      +---+    +----------+
</pre>
<dl>
<dt>MIMD: multiple instruction, multiple data</dt><dd><ul>
<li>am ehesten in verteilten Systemen anzutreffen</li>

</ul></dd>

</dl>
<pre class="example">
   +----------+    +---+    +----------+
   | D source |---&gt;| P |&lt;---| I source |
   +----------+    +---+    +----------+
   +----------+    +---+    +----------+
   | D source |---&gt;| P |&lt;---| I source |                  
   +----------+    +---+    +----------+
   +----------+    +---+    +----------+
   | D source |---&gt;| P |&lt;---| I source |
   +----------+    +---+    +----------+
</pre>

</section>
<section id="orgdc001bd">
<h4 id="orgdc001bd">Ausprägungen</h4>
<div class="outline-text-4" id="text-orgdc001bd">
</div>
</section>
<section id="orgd7fbafc">
<h5 id="orgd7fbafc">Eng gekoppelte Multiprozessoren und Multicore-Prozessoren</h5>
<ul>
<li>mehrere Prozesse können <i>echt</i> parallel ablaufen (auf
Einprozessorsystemen hingegen nur Quasi-Parallelität)</li>
<li>gemeinsamer Hauptspeicher</li>

</ul>
</section>
<section id="orgd7dde7c">
<h5 id="orgd7dde7c">Vektorrechner</h5>
<ul>
<li>Ausführung einer Berechnung gleichzeitig auf vielen Daten</li>
<li>Anordnung der Daten als Vektor bzw. Matrix</li>
<li>Beispiel für SIMD-Architektur</li>
<li>High-Performance-Computing</li>
<li>bekannt geworden ursprünglich durch Cray-Supercomputer (seit 1978)</li>
<li>genutzt z. B. für Simulationen (Meteorologie)</li>

</ul>
</section>
<section id="org81ed196">
<h5 id="org81ed196">Allzweckberechnungen auf Grafikprozessoren (GPGPU)</h5>
<ul>
<li>ursprünglich bestehend aus beschränkt programmierbaren
Spezialprozessoren für Fließkommaoperationen</li>
<li>inzwischen frei programmierbare Prozessoren (tausende von Kernen),
dadurch</li>
<li>nutzbar nicht nur für Grafikanwendungen</li>
<li>Verwendbarkeit in höheren Programmiersprachen durch spezielle
Bibliotheken wie z. B. CUDA von Nvidia</li>
<li>Beispiel für SIMD-Architektur</li>

</ul>
</section>
<section id="orgf0a763c">
<h5 id="orgf0a763c">Lose gekoppelte Multiprozessoren</h5>
<ul>
<li>kein gemeinsamer Speicher</li>
<li>Synchronisation und Kommunikation durch Nachrichtenaustausch</li>
<li>Ziele: Erhöhung der Leistung, Erhöhung der Verfügbarkeit</li>
<li>MIMD möglich</li>

</ul>
</section>
</section>
<section>
<section id="org957884c">
<h2 id="org957884c">Prozesse und Threads</h2>
<p>
(Die Ausführungen in diesem lehnen sich an ein Vorlesungsskript von
Uwe Neuhaus an)
</p>
<dl>
<dt>Prozess</dt><dd><ul>
<li>ein in Ausführung befindliches Programm</li>
<li>benötigt Ressourcen: Prozessor, Speicher (Programmcode, Daten,
Stack), Dateien, E/A-Geräte</li>
<li>bislang betrachtet: sequentiell arbeitende Prozesse (nur ein Ausführungsstrang)</li>

</ul></dd>
<dt>Thread</dt><dd><ul>
<li>ein Ausführungsstrang innerhalb eines Prozesses</li>
<li>benötigt: Prozessor, eigenen Stack</li>
<li>nutzt: Programmcode, Daten, Dateien, E/A-Geräte des Prozesses</li>
<li>Mehrere Threads innerhalb eines Prozesses möglich</li>

</ul></dd>

</dl>
</section>
<section >

<div class="figure">
<p><img src="./Abbildungen/prozessthreads.png" alt="prozessthreads.png" width="400px" />
</p>
</div>
</section>
<section id="orgee9f563">
<h3 id="orgee9f563">Beispiele für Multithreading</h3>
<ul>
<li>Anwendungen mit graphischer Benutzeroberfläche, z.&nbsp;B. Textverarbeitung:
<ul>
<li>Texteingabe</li>
<li>Rechtschreibprüfung</li>
<li>Ausdruck</li>

</ul></li>
<li>Serversoftware, z.&nbsp;B. Webserver, DB-Server:
<ul>
<li>Administration</li>
<li>Simultane Bearbeitung vieler Anfragen</li>

</ul></li>

</ul>
</section>
<section id="orgd1ccd70">
<h3 id="orgd1ccd70">Vorteile von Multithreading</h3>
<dl>
<dt>Kürzere Antwortzeiten</dt><dd>Bei interaktiven Anwendungen kann auch auf
Benutzereingaben reagiert werden, während andere, langandauernde
Aufgaben durchgeführt werden.</dd>
<dt>Gemeinsame Nutzung von Ressourcen</dt><dd>Auf gemeinsamen Speicher sowie
gemeinsame Dateien und E/A-Geräte kann ohne weiteren Aufwand
zugegriffen werden.</dd>
<dt>Wirtschaftlichkeit</dt><dd>Die Erzeugung eines neuen Threads und der
Wechsel zwischen zwei Threads eines Prozesses verursacht
erheblich weniger Auf- wand (im Vergleich zur
Prozesserzeugung/zum Prozesswechsel).</dd>
<dt>Nutzung von Multiprozessorarchitekturen</dt><dd>Auch ein einziger
multithreading Prozess kann gleichzeitig mehrere Prozessoren
nutzen.</dd>

</dl>
</section>
<section id="orgaa4a1e8">
<h3 id="orgaa4a1e8">Anwender- und Kernel-Threads</h3>
<dl>
<dt>Anwender-Threads</dt><dd>Erzeugung, Scheduling und Verwaltung der Threads
erfolgt über spezielle Programm-Bibliotheken auf Ebene des
Anwendungs&#x00ad;programms. Für den Kernel besteht das Programm aus
einem einzigen, single-threaded Prozess.
<dl>
<dt>Vorteil</dt><dd>effizient (Kernel muss nicht eingreifen)</dd>
<dt>Nachteil</dt><dd>Muss ein Thread warten, müssen es alle.</dd>

</dl></dd>
<dt>Kernel-Threads</dt><dd>Erzeugung, Scheduling und Verwaltung der Threads
werden durch das Betriebssystem unterstützt.
<dl>
<dt>Vorteile</dt><dd>Verteilung auf mehrere Prozessoren möglich; ein
wartender Thread behindert die anderen Threads nicht.</dd>

</dl></dd>

</dl>
</section>
<section id="org883efcc">
<h3 id="org883efcc">Multithreading-Modelle</h3>
<dl>
<dt>Many-to-One-Modell</dt><dd><ul>
<li>Mehrere Anwender-Threads werden auf einen Kernel-Thread abgebildet.</li>
<li>Beispiele: Green-Thread-Library bei Solaris 2, POSIX Pthread-
Library, Betriebssysteme ohne Thread-Unterstützung</li>

</ul></dd>
<dt>One-to-One-Modell</dt><dd><ul>
<li>Jeder Thread eines Anwendungsprogramms wird auf genau einen
Kernel-Thread abgebildet</li>
<li>Beispiele: Windows NT, Windows 2000, OS/2</li>

</ul></dd>
<dt>Many-to-Many-Modell</dt><dd><ul>
<li>Die Threads der Anwendungsprogramme werden auf eine Anzahl von Kernel-Threads gemultiplext.</li>
<li>Beispiele: IRIX, HP-UX, Tru64 UNIX</li>

</ul></dd>

</dl>
</section>
<section id="org37561de">
<h3 id="org37561de">Multithreading-Modelle: Many-to-One</h3>

<div class="figure">
<p><img src="./Abbildungen/manytoone.png" alt="manytoone.png" width="400px" />
</p>
</div>

</section>
<section id="orgfe6305b">
<h3 id="orgfe6305b">Multithreading-Modelle: One-to-One</h3>

<div class="figure">
<p><img src="./Abbildungen/onetoone.png" alt="onetoone.png" width="400px" />
</p>
</div>

</section>
<section id="orgf1d5204">
<h3 id="orgf1d5204">Multithreading-Modelle: Many-to-Many</h3>

<div class="figure">
<p><img src="./Abbildungen/manytomany.png" alt="manytomany.png" width="400px" />
</p>
</div>
</section>
<section id="org7e9d2fd">
<h3 id="org7e9d2fd">Scheduling</h3>
<ul>
<li>Scheduling in modernen Systemem: Die Zuteilung des Prozessors zu
einem Prozess bedeutet die Zuteilung des Prozessors zu einem seiner Threads.</li>

</ul>
<pre class="example">
  Process1    scheduled   +----------+
    Thread11-------------&gt;|processor3|
    Thread12              +----------+

  Process2
    Thread21
    Thread22  scheduled   +----------+
    Thread23-------------&gt;|processor7|
                          +----------+
</pre>

</section>
</section>
<section>
<section id="orgee59ccc">
<h2 id="orgee59ccc">weitere verwendete Literatur</h2>
<ul>
<li><a class='org-ref-reference' href="#CACM2017">CACM2017</a></li>
<li><a class='org-ref-reference' href="#CACM2016">CACM2016</a></li>

</ul>
</section>
</section>
<section>
<section id="org9f0a021">
<h2 id="org9f0a021"><h2>Literaturverzeichnis</h2>
<ul class='org-ref-bib'><li><a id="Bengel2015">[Bengel2015]</a> <a name="Bengel2015"></a>Günther Bengel, Christian Baun, Marcel Kunze & Karl-Uwe Stucky, Masterkurs Parallele und Verteilte Systeme, Springer Fachmedien Wiesbaden (2015).</li>
<li><a id="Kalin2015">[Kalin2015]</a> <a name="Kalin2015"></a>Martin Kalin, Concurrent and Parallel Programming Concepts, (2015), zuletzt aufgerufen am 10.10.2017: <a href="https://www.safaribooksonline.com/library/view/concurrent-and-parallel/9781771375313/">https://www.safaribooksonline.com/library/view/concurrent-and-parallel/9781771375313/</a> </li>
<li><a id="Flynn1972">[Flynn1972]</a> <a name="Flynn1972"></a>Flynn, Some Computer Organizations and Their Effectiveness, <i>IEEE Trans. Comput.</i>, <b>21(9)</b>, 948-960 (1972). <a href="http://dx.doi.org/10.1109/TC.1972.5009071">link</a>. <a href="http://dx.doi.org/10.1109/TC.1972.5009071">doi</a>.</li>
<li><a id="CACM2017">[CACM2017]</a> <a name="CACM2017"></a>Practical Parallelism, (2017), zuletzt aufgerufen am 26.09.2017: <a href="https://cacm.acm.org/careers/219104-practical-parallelism/fulltext">https://cacm.acm.org/careers/219104-practical-parallelism/fulltext</a> </li>
<li><a id="CACM2016">[CACM2016]</a> <a name="CACM2016"></a>Parallel Programming Made Easy, (2017), zuletzt aufgerufen am 26.09.2017: <a href="https://cacm.acm.org/careers/203794-parallel-programming-made-easy/fulltext">https://cacm.acm.org/careers/203794-parallel-programming-made-easy/fulltext</a> </li>
</ul></h2>
</section>
</section>
</div>
</div>
<script src="./reveal.js/lib/js/head.min.js"></script>
<script src="./reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: true,
progress: true,
history: false,
center: true,
slideNumber: 'c',
rollingLinks: false,
keyboard: true,
overview: true,
margin: 0.05,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'slide', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'default',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: './reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: './reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: './reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: './reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: './reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
,dependencies: [ { src: 'plugin/menu/menu.js', async: true }, { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true } ] , menu: {hideMissingTitles: true}});
</script>
</body>
</html>
